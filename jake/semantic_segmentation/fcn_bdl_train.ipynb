{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Semantic Segmentation Using DeepLab"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import datetime\n",
    "\n",
    "\n",
    "import itertools\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torchvision\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim # For all Optimization algorithms, SGD, Adam, etc.\n",
    "from torch.optim import lr_scheduler \n",
    "import torch.nn.functional as F  # All functions that don't have any parameters\n",
    "from torch.utils.data import DataLoader  # Gives easier dataset managment and creates mini batches\n",
    "import torchvision.datasets as datasets  # Has standard datasets we can import in a nice way\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_info():\n",
    "    r = torch.cuda.memory_reserved(0)/(2**30)\n",
    "    a = torch.cuda.memory_allocated(0)/(2**30)\n",
    "    f = r-a\n",
    "    print(f\"Total GPU mem: \\t{torch.cuda.get_device_properties(0).total_memory/(2**30)} GB\")\n",
    "    print(f\"Reserved: \\t{r} GB\")\n",
    "    print(f\"Allocated: \\t{a} GB\")\n",
    "    print(f\"Free: \\t\\t{f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_info()"
   ]
  },
  {
   "source": [
    "# Data Loading"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "im_size = 56*2\n",
    "\n",
    "x_transform =  transforms.Compose([#transforms.ToPILImage(),\n",
    "                    transforms.Resize(im_size),\n",
    "                    transforms.CenterCrop(im_size),\n",
    "                    transforms.ToTensor(), \n",
    "                    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n",
    "\n",
    "y_transform =  transforms.Compose([#transforms.ToPILImage(),\n",
    "                    transforms.Resize(im_size),\n",
    "                    transforms.CenterCrop(im_size),\n",
    "                    transforms.ToTensor()\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "source": [
    "train_dataset = datasets.VOCSegmentation(root=\"../dataset/\", year='2012', image_set='train', \n",
    "                                             download=False, transform=x_transform, target_transform=y_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "test_dataset = datasets.VOCSegmentation(root=\"../dataset/\", year='2012', image_set='val', \n",
    "                                             download=False, transform=x_transform, target_transform=y_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.segmentation.deeplabv3_resnet101(pretrained=True)\n",
    "model = models.segmentation.fcn_resnet101(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=255) # ignore (instance) contour\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out,labels):\n",
    "    im = out.argmax(1) # [batch_size x classes x H x W] -> [batch_size x H x W]\n",
    "    correct = 0\n",
    "    correct += (out.argmax(1) == labels).sum() # for each pixel check if match\n",
    "\n",
    "    return 100*correct/(im_size*im_size*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningConfusionMatrix():\n",
    "    def __init__(self, labels, ignore_label=255):\n",
    "        \n",
    "        self.labels = labels\n",
    "        self.ignore_label = ignore_label\n",
    "        self.overall_confusion_matrix = None\n",
    "        self.SMOOTH = 1e-6\n",
    "        self.miou = 0\n",
    "        self.acc  = 0 \n",
    "        \n",
    "    def update_matrix(self, ground_truth, prediction):\n",
    "        # if (ground_truth == self.ignore_label).all():\n",
    "        #     return\n",
    "        \n",
    "        current_confusion_matrix = confusion_matrix(y_true=ground_truth,\n",
    "                                                    y_pred=prediction,\n",
    "                                                    labels=self.labels)\n",
    "        \n",
    "        if self.overall_confusion_matrix is not None:\n",
    "            \n",
    "            self.overall_confusion_matrix += current_confusion_matrix\n",
    "        else:\n",
    "            \n",
    "            self.overall_confusion_matrix = current_confusion_matrix\n",
    "    \n",
    "    def compute_current_mean_intersection_over_union(self):\n",
    "        \n",
    "        intersection = np.diag(self.overall_confusion_matrix)\n",
    "        ground_truth_set = self.overall_confusion_matrix.sum(axis=1)\n",
    "        predicted_set = self.overall_confusion_matrix.sum(axis=0)\n",
    "        union =  ground_truth_set + predicted_set - intersection\n",
    "\n",
    "        intersection_over_union = (intersection + self.SMOOTH) / (union.astype(np.float32) + self.SMOOTH)\n",
    "        mean_intersection_over_union = np.mean(intersection_over_union)\n",
    "\n",
    "        pixel_accuracy = np.sum(intersection)/np.sum(self.overall_confusion_matrix)\n",
    "\n",
    "        self.miou = mean_intersection_over_union\n",
    "        self.acc  = pixel_accuracy\n",
    "\n",
    "\n",
    "        return mean_intersection_over_union,pixel_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actu = [2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1, 2]\n",
    "y_pred = [0, 0, 2, 1, 0, 2, 1, 0, 2, 0, 2, 2]\n",
    "conf = confusion_matrix(y_actu, y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia = np.diag(conf).sum()\n",
    "sumall = np.sum(conf)\n",
    "print(dia)\n",
    "print(sumall)\n",
    "print(dia/sumall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "source": [
    "## Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "    for batch_idx, (data, targets) in loop:\n",
    "\n",
    "        data = data.to(device=device)\n",
    "        if (int(targets.max()) == int(1)): # scale from [0,1] -> [0,255]\n",
    "            targets = targets*255\n",
    "        targets = targets.squeeze(1).to(device=device, dtype=torch.int64)\n",
    "        \n",
    "        # forward pass\n",
    "        out = model(data)['out']\n",
    "        loss = criterion(out, targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent\n",
    "        optimizer.step()\n",
    "\n",
    "        # update progress bar\n",
    "        acc = accuracy(out, targets)\n",
    "        loop.set_description(f\"Epoch [{epoch}/{num_epochs}]\")\n",
    "        loop.set_postfix(loss = loss.item(), acc=f\"{acc:.0f}%\")\n",
    "\n",
    "\n",
    "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one epoch with batch_size:16, im_size: 112 was 13 minutes"
   ]
  },
  {
   "source": [
    "# Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the helper function\r\n",
    "def decode_segmap(image, nc=21):\r\n",
    "  \r\n",
    "  label_colors = np.array([(0, 0, 0),  # 0=background\r\n",
    "               # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle\r\n",
    "               (128, 0, 0), (0, 128, 0), (128, 128, 0), (0, 0, 128), (128, 0, 128),\r\n",
    "               # 6=bus, 7=car, 8=cat, 9=chair, 10=cow\r\n",
    "               (0, 128, 128), (128, 128, 128), (64, 0, 0), (192, 0, 0), (64, 128, 0),\r\n",
    "               # 11=dining table, 12=dog, 13=horse, 14=motorbike, 15=person\r\n",
    "               (192, 128, 0), (64, 0, 128), (192, 0, 128), (64, 128, 128), (192, 128, 128),\r\n",
    "               # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\r\n",
    "               (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0), (0, 64, 128)])\r\n",
    "\r\n",
    "  r = np.zeros_like(image).astype(np.uint8)\r\n",
    "  g = np.zeros_like(image).astype(np.uint8)\r\n",
    "  b = np.zeros_like(image).astype(np.uint8)\r\n",
    "  \r\n",
    "  for l in range(0, nc):\r\n",
    "    idx = image == l\r\n",
    "    r[idx] = label_colors[l, 0]\r\n",
    "    g[idx] = label_colors[l, 1]\r\n",
    "    b[idx] = label_colors[l, 2]\r\n",
    "    \r\n",
    "  rgb = np.stack([r, g, b], axis=2)\r\n",
    "  return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "labels = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "cm = RunningConfusionMatrix(labels=labels, ignore_label=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, batch_size=4, overlay=False):\n",
    "    model.eval()\n",
    "\n",
    "    loop = tqdm(enumerate(test_loader), total=len(test_loader), leave=False)\n",
    "    for batch_idx, (data, targets) in loop:\n",
    "        image, target = next(iter(test_loader))\n",
    "        image, target = image.to(device), target.to(device)\n",
    "        if (int(target.max()) == int(1)):\n",
    "            target = target*255\n",
    "        out = model(image)['out']\n",
    "\n",
    "        image, target, out = image.cpu(), target.cpu(), out.cpu()\n",
    "        image, target, out = image.to('cpu'), target.to('cpu'), out.to('cpu')\n",
    "\n",
    "\n",
    "        cm.update_matrix(target.view(-1), out.argmax(1).view(-1))\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            for idx in range(batch_size):\n",
    "                \n",
    "                om = torch.argmax(out[idx].squeeze(), dim=0).detach().cpu().numpy()\n",
    "\n",
    "                input_image  = image[idx].permute(1,2,0) * std[0] + torch.FloatTensor(mean)\n",
    "                target_image = decode_segmap(target[idx].squeeze(0))\n",
    "                output_image = decode_segmap(om)\n",
    "\n",
    "                if (overlay):\n",
    "                    axes=[]\n",
    "                    fig=plt.figure(figsize=(6,6))\n",
    "                    plt.imshow(torch.FloatTensor(output_image) * 0.0033 + input_image * 0.65 )\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    axes=[]\n",
    "                    fig=plt.figure(figsize=(21,21))\n",
    "                    axes.append( fig.add_subplot(1, 3, 1) )\n",
    "                    plt.imshow( input_image  )\n",
    "                    axes[-1].set_title(\"input\")\n",
    "\n",
    "                    axes.append( fig.add_subplot(1, 3, 2) )\n",
    "                    plt.imshow( target_image )\n",
    "                    axes[-1].set_title(\"target\")\n",
    "\n",
    "                    axes.append( fig.add_subplot(1, 3, 3) )\n",
    "                    plt.imshow( output_image )\n",
    "                    axes[-1].set_title(\"output\")\n",
    "\n",
    "                    plt.show()\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    model.train()\n",
    "    print(f\"mean intersection over union: {cm.compute_current_mean_intersection_over_union()}\")   \n",
    "    plot_confusion_matrix(cm.overall_confusion_matrix,labels)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, test_loader, overlay=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"0: background\",\"1: aeroplane\", \"2: bicycle\", \"3: bird\", \"4: boat\", \"5: bottle\", \"6: bus\", \"7: car\", \"8: cat\", \"9: chair\", \"10: cow\", \"11: dining table\", \"12: dog\", \"13: horse\", \"14: motorbike\", \"15: person \",\"16: potted plant\", \"17: sheep\", \"18: sofa\", \"19: train\", \"20: tv/monitor\"]\n",
    "plot_confusion_matrix(cm.overall_confusion_matrix,labels, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = cm.compute_current_mean_intersection_over_union()\n",
    "print(\"the mIoU is: \\t\\t%.2f\"  % metrics[0])\n",
    "print(\"the pixel accuracy is: \\t%.2f\"  % metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palette = torch.tensor([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\n",
    "# colors = torch.as_tensor([i for i in range(21)])[:, None] * palette\n",
    "# colors = (colors % 255).numpy().astype(\"uint8\")\n",
    "\n",
    "# # plot the semantic segmentation predictions of 21 classes in each color\n",
    "# r = Image.fromarray(out[0].argmax(0).byte().cpu().numpy()).resize(im.size)\n",
    "# r.putpalette(colors)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"0: background\", \"1: aeroplane\", \"2: bicycle\", \"3: bird\", \"4: boat\", \"5: bottle\", \"6: bus\", \"7: car\", \"8: cat\", \"9: chair\", \"10: cow\", \"11: dining table\", \"12: dog\", \"13: horse\", \"14: motorbike\", \"15: person \",\"16: potted plant\", \"17: sheep\", \"18: sofa\", \"19: train\", \"20: tv/monitor\"]\n",
    "\n",
    "width = 2\n",
    "height = 2\n",
    "rows = 6\n",
    "cols = 7\n",
    "\n",
    "axes=[]\n",
    "fig=plt.figure(figsize=(13,13))\n",
    "\n",
    "for a in range(21):\n",
    "    # b = np.random.randint(7, size=(height,width))\n",
    "    axes.append( fig.add_subplot(rows, cols, a+1) )\n",
    "    subplot_title=(str(labels[a]))\n",
    "    axes[-1].set_title(subplot_title,fontweight=\"bold\")\n",
    "    z = np.array([[a, a],[a, a]])\n",
    "    plt.imshow(decode_segmap(z))\n",
    "    plt.axis('off')  \n",
    "# fig.tight_layout()    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model1.ckpt')"
   ]
  }
 ]
}