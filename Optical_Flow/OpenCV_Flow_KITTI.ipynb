{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('deeplearning': conda)",
   "metadata": {
    "interpreter": {
     "hash": "2bd64c8ed255417a6a958191fccf12000a54ee5f0beba3cab0ff9b85bda4afbd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, flow=False):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if flow:\n",
    "            img = cv2.imread(os.path.join(folder,filename), -1)\n",
    "        else:\n",
    "            img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image, name=\"image\"):\n",
    "    cv2.imshow(name,image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "\terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "\terr /= float(imageA.shape[0] * imageA.shape[1])\n",
    "\treturn err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_transform(array):\n",
    "    assert(isinstance(array, np.ndarray))\n",
    "    array = np.transpose(array, (2, 0, 1))\n",
    "    # handle numpy array\n",
    "    tensor = torch.from_numpy(array)\n",
    "    # put it from HWC to CHW format\n",
    "    return tensor.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow2rgb(flow, hsv):\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    hsv = np.float32(hsv)\n",
    "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "    return rgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OpticalFlow(frame1, frame2, display=False, together=False):\n",
    "    hsv = np.zeros_like(frame1)\n",
    "    hsv[...,1] = 255\n",
    "    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_RGB2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(frame1_gray,frame2_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    if display:\n",
    "        rgb = flow2rgb(flow, hsv)\n",
    "        if not together:\n",
    "            show(rgb)\n",
    "        else:\n",
    "            stacked = np.vstack((frame1,rgb))\n",
    "            show(stacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand-crafted transformation\n",
    "def apply_flow(frame1, frame2, flow):\n",
    "    # recon = frame2.copy()\n",
    "    # recon = np.zeros_like(frame2)\n",
    "    recon = frame1.copy()\n",
    "    height = len(frame1)\n",
    "    width = len(frame1[0])\n",
    "\n",
    "    for h in range(height):\n",
    "        for w in range(width):\n",
    "            vec = flow[h,w,:]   # 2D vector containing OF of pixel (h,w)\n",
    "            if mag(vec) > 0:\n",
    "                dx = round(vec[0].item()) # x part of vector\n",
    "                dy = round(vec[1].item()) # y part of vector\n",
    "                h_new = h+dy if h+dy < height else height-1 # make sure index stays in bounds\n",
    "                w_new = w+dx if w+dx < width else width-1\n",
    "                recon[h_new, w_new, :] = frame1[h, w, :]\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    return recon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flow_from_png(flo_file):\n",
    "    # flo_file = cv2.imread(png_path, -1)\n",
    "    flo_img = flo_file[:,:,2:0:-1].astype(np.float32)\n",
    "    invalid = (flo_file[:,:,0] == 0)\n",
    "    flo_img = flo_img - 32768\n",
    "    flo_img = flo_img / 64\n",
    "    flo_img[np.abs(flo_img) < 1e-10] = 1e-10\n",
    "    flo_img[invalid, :] = 0\n",
    "    return(flo_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag(vec):\n",
    "    return np.sqrt(vec[0]**2+vec[1]**2)"
   ]
  },
  {
   "source": [
    "# Loading A & B"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_path = r\"C:\\Users\\20182475\\OneDrive - TU Eindhoven\\TUe documents\\BAU3\\Honors - Smart Mobility\\DATA\\image_20_to_be_converted_to_cv\\A\"\n",
    "B_path = r\"C:\\Users\\20182475\\OneDrive - TU Eindhoven\\TUe documents\\BAU3\\Honors - Smart Mobility\\DATA\\image_20_to_be_converted_to_cv\\B\"\n",
    "flow_path = r\"C:\\Users\\20182475\\OneDrive - TU Eindhoven\\TUe documents\\BAU3\\Honors - Smart Mobility\\DATA\\flow_20_to_be_converted_to_cv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = load_images_from_folder(A_path)\n",
    "B = load_images_from_folder(B_path)\n",
    "flow_ = load_images_from_folder(flow_path, flow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 12\n",
    "show(A[i])\n",
    "show(B[i])\n",
    "# mse(A[i],B[i])"
   ]
  },
  {
   "source": [
    "# Calculate OF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-27ebdff9ab27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mOpticalFlow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtogether\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "OpticalFlow(A[i], B[i], display=True, together=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(4):\n",
    "    OpticalFlow(A[i], B[i], display=True, together=True)"
   ]
  },
  {
   "source": [
    "# Apply Transformation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow from 3d to 2d\n",
    "flow = []\n",
    "for i in range(len(flow_)):\n",
    "    flow.append(load_flow_from_png(flow_[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-42b2cf8dc6bf>\u001b[0m in \u001b[0;36mapply_flow\u001b[1;34m(frame1, frame2, flow)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mw_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdx\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdx\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mrecon\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrecon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# reconstruct frame2 given frame1 and flow1->2, save them\n",
    "\n",
    "for i in range(len(A)):\n",
    "    reconstructed = apply_flow(A[i], B[i], flow[i])\n",
    "    clear_output(wait=True)\n",
    "    print(i)\n",
    "    # cv2.imwrite('reconstructed_using_transform/reconstructed_'+ str(i) + \".png\", reconstructed)\n",
    "    cv2.imshow(i, reconstructed)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5577052592992109"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "vec = flow[0][200,600]\n",
    "mag = np.sqrt(vec[0]**2+vec[1]**2)\n",
    "mag"
   ]
  },
  {
   "source": [
    "# Apply flow2rgb for ground truths"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, fl in enumerate(flow):\n",
    "    hsv = np.zeros((len(fl), len(fl[0]), 3))\n",
    "    hsv[...,1] = 255\n",
    "    rgb = flow2rgb(fl, hsv)\n",
    "    if i < 3:\n",
    "        show(rgb)\n",
    "    cv2.imwrite('groundtruth_rgb/gt_'+ str(144+i) + \".png\", rgb)\n"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}