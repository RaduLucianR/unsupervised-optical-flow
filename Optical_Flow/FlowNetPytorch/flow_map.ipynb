{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('deeplearning': conda)",
   "metadata": {
    "interpreter": {
     "hash": "2bd64c8ed255417a6a958191fccf12000a54ee5f0beba3cab0ff9b85bda4afbd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\Users\\20182475\\OneDrive - TU Eindhoven\\TUe documents\\BAU3\\Honors - Smart Mobility\\deeplearning-notebooks\\Optical_Flow\\FlowNetPytorch\\models\\util.py:10: ImportWarning: failed to load custom correlation modulewhich is needed for FlowNetC\n  warnings.warn(\"failed to load custom correlation module\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import flow_transforms\n",
    "import models\n",
    "import datasets\n",
    "from multiscaleloss import multiscaleEPE, realEPE\n",
    "from util import flow2rgb, AverageMeter, save_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=[0.45,0.432,0.411]\n",
    "mean=[0,0,0]\n",
    "input_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "    transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "    transforms.Normalize(mean=mean, std=[1,1,1])\n",
    "])\n",
    "target_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "    transforms.Normalize(mean=[0,0],std=[20*0+1,20*0+1])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_transform = flow_transforms.Compose([\n",
    "            flow_transforms.RandomTranslate(10),\n",
    "            flow_transforms.RandomRotate(10,5),\n",
    "            flow_transforms.RandomCrop((320,448)),\n",
    "            flow_transforms.RandomVerticalFlip(),\n",
    "            flow_transforms.RandomHorizontalFlip()\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r\"KITTI_split\\training_80\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=> fetching img pairs in 'KITTI_split\\training_80'\n144 samples found, 144 train samples and 0 test samples \n"
     ]
    }
   ],
   "source": [
    "print(\"=> fetching img pairs in '{}'\".format(data))\n",
    "train_set, test_set = datasets.__dict__[\"KITTI_noc\"](\n",
    "    data,\n",
    "    transform=input_transform,\n",
    "    target_transform=target_transform,\n",
    "    co_transform=None,\n",
    "    split=1.0\n",
    ")\n",
    "print('{} samples found, {} train samples and {} test samples '.format(len(test_set)+len(train_set),\n",
    "                                                                        len(train_set),\n",
    "                                                                        len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=1,\n",
    "        num_workers=1, pin_memory=True, shuffle=True)\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     test_set, batch_size=0,\n",
    "#     num_workers=1, pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n"
     ]
    }
   ],
   "source": [
    "for i, (input, target) in enumerate(train_loader):\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, target = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "im1 = input[0][i].numpy().transpose(1, 2, 0)\n",
    "im2 = input[1][i].numpy().transpose(1, 2, 0)\n",
    "im3 = input[0][i+1].numpy().transpose(1, 2, 0)\n",
    "im4 = input[1][i+1].numpy().transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = im1[...,::-1].copy()\n",
    "im2 = im2[...,::-1].copy()\n",
    "im3 = im3[...,::-1].copy()\n",
    "im4 = im4[...,::-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"1\", im1)\n",
    "cv2.imshow(\"2\", im2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "## MSE of two input images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "\t# the 'Mean Squared Error' between the two images is the\n",
    "\t# sum of the squared difference between the two images;\n",
    "\t# NOTE: the two images must have the same dimension\n",
    "\terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "\terr /= float(imageA.shape[0] * imageA.shape[1])\n",
    "\t\n",
    "\t# return the MSE, the lower the error, the more \"similar\"\n",
    "\t# the two images are\n",
    "\treturn err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.16918404435096754"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "mse(im1,im2)"
   ]
  },
  {
   "source": [
    "## Applying Flow Map on Image 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg1 = target[0].permute(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = np.zeros_like(im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1242, 375)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "width = len(im1[0])\n",
    "height = len(im1)\n",
    "width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "image 1 shape: \t(375, 1242, 3)\nrecon shape: \t(375, 1242, 3)\ntarget shape: \t(375, 1242, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"image 1 shape: \\t{im1.shape}\")\n",
    "print(f\"recon shape: \\t{recon.shape}\")\n",
    "print(f\"target shape: \\t{tg1.numpy().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# recon = np.zeros_like(im1)\n",
    "recon = im2.copy()\n",
    "\n",
    "for h in range(height):\n",
    "    for w in range(width):\n",
    "        vec = tg1[h,w,:]   # 2D vector containing OF of pixel (h,w)\n",
    "        dx = round(vec[0].item()) # x part of vector\n",
    "        dy = round(vec[1].item()) # y part of vector\n",
    "        h_new = h+dy if h+dy < height else height-1 # make sure index stays in bounds\n",
    "        w_new = w+dx if w+dx < width else width-1\n",
    "        \n",
    "        recon[h_new, w_new, :] = im1[h, w, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"image1\", im1)\n",
    "cv2.imshow(\"image2\", im2)\n",
    "cv2.imshow(\"recon\", recon)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mse im1 and im2: 0.17\nmse im2 and recon: 0.15307593408474898\n"
     ]
    }
   ],
   "source": [
    "print(f\"mse im1 and im2: {mse(im1,im2):.2f}\")\n",
    "print(f\"mse im2 and recon: {mse(im2,recon)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}