{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation Using DeepLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# loading libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import datetime\n",
    "\n",
    "\n",
    "import itertools\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torchvision\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim # For all Optimization algorithms, SGD, Adam, etc.\n",
    "from torch.optim import lr_scheduler \n",
    "import torch.nn.functional as F  # All functions that don't have any parameters\n",
    "from torch.utils.data import DataLoader  # Gives easier dataset managment and creates mini batches\n",
    "import torchvision.datasets as datasets  # Has standard datasets we can import in a nice way\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_layers = {'layer4': 'out'}\n",
    "return_layers['layer3'] = 'aux'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer4': 'out', 'layer3': 'aux'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pynvml import *\n",
    "# nvmlInit()\n",
    "# h = nvmlDeviceGetHandleByIndex(0)\n",
    "# info = nvmlDeviceGetMemoryInfo(h)\n",
    "# print(f'total    : {info.total}')\n",
    "# print(f'free     : {info.free}')\n",
    "# print(f'used     : {info.used}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory/(2**30)\n",
    "r = torch.cuda.memory_reserved(0)/(2**30)\n",
    "a = torch.cuda.memory_allocated(0)/(2**30)\n",
    "f = r-a  # free inside reserved\n",
    "print(t)\n",
    "print(r)\n",
    "print(a)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "im_size = 56*2\n",
    "\n",
    "x_transform =  transforms.Compose([#transforms.ToPILImage(),\n",
    "                    transforms.Resize(im_size),\n",
    "                    transforms.CenterCrop(im_size),\n",
    "                    transforms.ToTensor(), \n",
    "                    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n",
    "\n",
    "y_transform =  transforms.Compose([#transforms.ToPILImage(),\n",
    "                    transforms.Resize(im_size),\n",
    "                    transforms.CenterCrop(im_size),\n",
    "                    transforms.ToTensor()\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.VOCSegmentation(root=\"D:\\Desktop\\Folder\\Jupyter\\data\", year='2012', image_set='train', \n",
    "                                             download=False, transform=x_transform, target_transform=y_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "test_dataset = datasets.VOCSegmentation(root=\"D:\\Desktop\\Folder\\Jupyter\\data\", year='2012', image_set='val', \n",
    "                                             download=False, transform=x_transform, target_transform=y_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/fcn_resnet101_coco-7ecb50ca.pth\" to C:\\Users\\20191039/.cache\\torch\\hub\\checkpoints\\fcn_resnet101_coco-7ecb50ca.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70e1c4f04354adc841c0995c572ea82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=217800805), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model = models.segmentation.deeplabv3_resnet101(pretrained=True)\n",
    "model = models.segmentation.fcn_resnet101(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fcn8(torch.nn.Module):\n",
    "    def __init__(self, num_classes = 21):\n",
    "        super(Fcn8, self).__init__()\n",
    "        features = list(vgg16(pretrained = True).features)\n",
    "        self.features = nn.ModuleList(features).eval()\n",
    "        self.vgg16 = vgg16(pretrained = True).features\n",
    "        \n",
    "        self.fc6 = nn.Conv2d(512, 4096, 7)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.drop6 = nn.Dropout2d()\n",
    "\n",
    "        # fc7\n",
    "        self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.drop7 = nn.Dropout2d()\n",
    "\n",
    "        self.score_fr = nn.Conv2d(4096, num_classes, 1)\n",
    "        self.score_pool3 = nn.Conv2d(256, num_classes, 1)\n",
    "        self.score_pool4 = nn.Conv2d(512, num_classes, 1)\n",
    "        \n",
    "        self.upscore2 = nn.ConvTranspose2d(\n",
    "            num_classes, num_classes, 4, stride=2, bias=False)\n",
    "        self.upscore8 = nn.ConvTranspose2d(\n",
    "            num_classes, num_classes, 16, stride=8, bias=False)\n",
    "        self.upscore_pool4 = nn.ConvTranspose2d(\n",
    "            num_classes, num_classes, 4, stride=2, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pool_layers = []\n",
    "        h = x\n",
    "        for ii, layer in enumerate(self.features):\n",
    "            h = layer(h)\n",
    "            if ii in {16,23,30}: #the 16th layer is pool3, the 23rd layer is pool4\n",
    "                pool_layers.append(h)\n",
    "        \n",
    "        pool3 = pool_layers[0]\n",
    "        pool4 = pool_layers[1]\n",
    "        pool5 = pool_layers[2]\n",
    "        \n",
    "        \n",
    "        h = self.relu6(self.fc6(h))\n",
    "        h = self.drop6(h)\n",
    "\n",
    "        h = self.relu7(self.fc7(h))\n",
    "        fc7_response = self.drop7(h)\n",
    "\n",
    "        h = self.score_fr(fc7_response)\n",
    "        h = self.upscore2(h)\n",
    "        upscore2 = h  # 1/16\n",
    "\n",
    "        h = self.score_pool4(pool4*0.01)  \n",
    "        h = h[:, :, 5:5 + upscore2.size()[2], 5:5 + upscore2.size()[3]]\n",
    "        score_pool4c = h  # 1/16\n",
    "\n",
    "        h = upscore2 + score_pool4c  # 1/16\n",
    "        h = self.upscore_pool4(h)\n",
    "        upscore_pool4 = h  # 1/8\n",
    "\n",
    "        h = self.score_pool3(pool3*0.0001)  \n",
    "        h = h[:, :,\n",
    "              9:9 + upscore_pool4.size()[2],\n",
    "              9:9 + upscore_pool4.size()[3]]\n",
    "        score_pool3c = h  # 1/8\n",
    "\n",
    "        h = upscore_pool4 + score_pool3c  # 1/8\n",
    "\n",
    "        h = self.upscore8(h)\n",
    "        h = h[:, :, 31:31 + x.size()[2], 31:31 + x.size()[3]].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn8 = Fcn8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fcn8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       1,792\n",
      "|    └─ReLU: 2-2                         --\n",
      "|    └─Conv2d: 2-3                       36,928\n",
      "|    └─ReLU: 2-4                         --\n",
      "|    └─MaxPool2d: 2-5                    --\n",
      "|    └─Conv2d: 2-6                       73,856\n",
      "|    └─ReLU: 2-7                         --\n",
      "|    └─Conv2d: 2-8                       147,584\n",
      "|    └─ReLU: 2-9                         --\n",
      "|    └─MaxPool2d: 2-10                   --\n",
      "|    └─Conv2d: 2-11                      295,168\n",
      "|    └─ReLU: 2-12                        --\n",
      "|    └─Conv2d: 2-13                      590,080\n",
      "|    └─ReLU: 2-14                        --\n",
      "|    └─Conv2d: 2-15                      590,080\n",
      "|    └─ReLU: 2-16                        --\n",
      "|    └─MaxPool2d: 2-17                   --\n",
      "|    └─Conv2d: 2-18                      1,180,160\n",
      "|    └─ReLU: 2-19                        --\n",
      "|    └─Conv2d: 2-20                      2,359,808\n",
      "|    └─ReLU: 2-21                        --\n",
      "|    └─Conv2d: 2-22                      2,359,808\n",
      "|    └─ReLU: 2-23                        --\n",
      "|    └─MaxPool2d: 2-24                   --\n",
      "|    └─Conv2d: 2-25                      2,359,808\n",
      "|    └─ReLU: 2-26                        --\n",
      "|    └─Conv2d: 2-27                      2,359,808\n",
      "|    └─ReLU: 2-28                        --\n",
      "|    └─Conv2d: 2-29                      2,359,808\n",
      "|    └─ReLU: 2-30                        --\n",
      "|    └─MaxPool2d: 2-31                   --\n",
      "├─AdaptiveAvgPool2d: 1-2                 --\n",
      "├─Sequential: 1-3                        --\n",
      "|    └─Linear: 2-32                      102,764,544\n",
      "|    └─ReLU: 2-33                        --\n",
      "|    └─Dropout: 2-34                     --\n",
      "|    └─Linear: 2-35                      16,781,312\n",
      "|    └─ReLU: 2-36                        --\n",
      "|    └─Dropout: 2-37                     --\n",
      "|    └─Linear: 2-38                      4,097,000\n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Sequential: 1-1                        --\n",
       "|    └─Conv2d: 2-1                       1,792\n",
       "|    └─ReLU: 2-2                         --\n",
       "|    └─Conv2d: 2-3                       36,928\n",
       "|    └─ReLU: 2-4                         --\n",
       "|    └─MaxPool2d: 2-5                    --\n",
       "|    └─Conv2d: 2-6                       73,856\n",
       "|    └─ReLU: 2-7                         --\n",
       "|    └─Conv2d: 2-8                       147,584\n",
       "|    └─ReLU: 2-9                         --\n",
       "|    └─MaxPool2d: 2-10                   --\n",
       "|    └─Conv2d: 2-11                      295,168\n",
       "|    └─ReLU: 2-12                        --\n",
       "|    └─Conv2d: 2-13                      590,080\n",
       "|    └─ReLU: 2-14                        --\n",
       "|    └─Conv2d: 2-15                      590,080\n",
       "|    └─ReLU: 2-16                        --\n",
       "|    └─MaxPool2d: 2-17                   --\n",
       "|    └─Conv2d: 2-18                      1,180,160\n",
       "|    └─ReLU: 2-19                        --\n",
       "|    └─Conv2d: 2-20                      2,359,808\n",
       "|    └─ReLU: 2-21                        --\n",
       "|    └─Conv2d: 2-22                      2,359,808\n",
       "|    └─ReLU: 2-23                        --\n",
       "|    └─MaxPool2d: 2-24                   --\n",
       "|    └─Conv2d: 2-25                      2,359,808\n",
       "|    └─ReLU: 2-26                        --\n",
       "|    └─Conv2d: 2-27                      2,359,808\n",
       "|    └─ReLU: 2-28                        --\n",
       "|    └─Conv2d: 2-29                      2,359,808\n",
       "|    └─ReLU: 2-30                        --\n",
       "|    └─MaxPool2d: 2-31                   --\n",
       "├─AdaptiveAvgPool2d: 1-2                 --\n",
       "├─Sequential: 1-3                        --\n",
       "|    └─Linear: 2-32                      102,764,544\n",
       "|    └─ReLU: 2-33                        --\n",
       "|    └─Dropout: 2-34                     --\n",
       "|    └─Linear: 2-35                      16,781,312\n",
       "|    └─ReLU: 2-36                        --\n",
       "|    └─Dropout: 2-37                     --\n",
       "|    └─Linear: 2-38                      4,097,000\n",
       "=================================================================\n",
       "Total params: 138,357,544\n",
       "Trainable params: 138,357,544\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(vgg16())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 64, 224, 224]        1,792\n",
      "├─ReLU: 1-2                              [-1, 64, 224, 224]        --\n",
      "├─Conv2d: 1-3                            [-1, 64, 224, 224]        36,928\n",
      "├─ReLU: 1-4                              [-1, 64, 224, 224]        --\n",
      "├─MaxPool2d: 1-5                         [-1, 64, 112, 112]        --\n",
      "├─Conv2d: 1-6                            [-1, 128, 112, 112]       73,856\n",
      "├─ReLU: 1-7                              [-1, 128, 112, 112]       --\n",
      "├─Conv2d: 1-8                            [-1, 128, 112, 112]       147,584\n",
      "├─ReLU: 1-9                              [-1, 128, 112, 112]       --\n",
      "├─MaxPool2d: 1-10                        [-1, 128, 56, 56]         --\n",
      "├─Conv2d: 1-11                           [-1, 256, 56, 56]         295,168\n",
      "├─ReLU: 1-12                             [-1, 256, 56, 56]         --\n",
      "├─Conv2d: 1-13                           [-1, 256, 56, 56]         590,080\n",
      "├─ReLU: 1-14                             [-1, 256, 56, 56]         --\n",
      "├─Conv2d: 1-15                           [-1, 256, 56, 56]         590,080\n",
      "├─ReLU: 1-16                             [-1, 256, 56, 56]         --\n",
      "├─MaxPool2d: 1-17                        [-1, 256, 28, 28]         --\n",
      "├─Conv2d: 1-18                           [-1, 512, 28, 28]         1,180,160\n",
      "├─ReLU: 1-19                             [-1, 512, 28, 28]         --\n",
      "├─Conv2d: 1-20                           [-1, 512, 28, 28]         2,359,808\n",
      "├─ReLU: 1-21                             [-1, 512, 28, 28]         --\n",
      "├─Conv2d: 1-22                           [-1, 512, 28, 28]         2,359,808\n",
      "├─ReLU: 1-23                             [-1, 512, 28, 28]         --\n",
      "├─MaxPool2d: 1-24                        [-1, 512, 14, 14]         --\n",
      "├─Conv2d: 1-25                           [-1, 512, 14, 14]         2,359,808\n",
      "├─ReLU: 1-26                             [-1, 512, 14, 14]         --\n",
      "├─Conv2d: 1-27                           [-1, 512, 14, 14]         2,359,808\n",
      "├─ReLU: 1-28                             [-1, 512, 14, 14]         --\n",
      "├─Conv2d: 1-29                           [-1, 512, 14, 14]         2,359,808\n",
      "├─ReLU: 1-30                             [-1, 512, 14, 14]         --\n",
      "├─MaxPool2d: 1-31                        [-1, 512, 7, 7]           --\n",
      "==========================================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 15.35\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 103.36\n",
      "Params size (MB): 56.13\n",
      "Estimated Total Size (MB): 160.07\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv2d: 1-1                            [-1, 64, 224, 224]        1,792\n",
       "├─ReLU: 1-2                              [-1, 64, 224, 224]        --\n",
       "├─Conv2d: 1-3                            [-1, 64, 224, 224]        36,928\n",
       "├─ReLU: 1-4                              [-1, 64, 224, 224]        --\n",
       "├─MaxPool2d: 1-5                         [-1, 64, 112, 112]        --\n",
       "├─Conv2d: 1-6                            [-1, 128, 112, 112]       73,856\n",
       "├─ReLU: 1-7                              [-1, 128, 112, 112]       --\n",
       "├─Conv2d: 1-8                            [-1, 128, 112, 112]       147,584\n",
       "├─ReLU: 1-9                              [-1, 128, 112, 112]       --\n",
       "├─MaxPool2d: 1-10                        [-1, 128, 56, 56]         --\n",
       "├─Conv2d: 1-11                           [-1, 256, 56, 56]         295,168\n",
       "├─ReLU: 1-12                             [-1, 256, 56, 56]         --\n",
       "├─Conv2d: 1-13                           [-1, 256, 56, 56]         590,080\n",
       "├─ReLU: 1-14                             [-1, 256, 56, 56]         --\n",
       "├─Conv2d: 1-15                           [-1, 256, 56, 56]         590,080\n",
       "├─ReLU: 1-16                             [-1, 256, 56, 56]         --\n",
       "├─MaxPool2d: 1-17                        [-1, 256, 28, 28]         --\n",
       "├─Conv2d: 1-18                           [-1, 512, 28, 28]         1,180,160\n",
       "├─ReLU: 1-19                             [-1, 512, 28, 28]         --\n",
       "├─Conv2d: 1-20                           [-1, 512, 28, 28]         2,359,808\n",
       "├─ReLU: 1-21                             [-1, 512, 28, 28]         --\n",
       "├─Conv2d: 1-22                           [-1, 512, 28, 28]         2,359,808\n",
       "├─ReLU: 1-23                             [-1, 512, 28, 28]         --\n",
       "├─MaxPool2d: 1-24                        [-1, 512, 14, 14]         --\n",
       "├─Conv2d: 1-25                           [-1, 512, 14, 14]         2,359,808\n",
       "├─ReLU: 1-26                             [-1, 512, 14, 14]         --\n",
       "├─Conv2d: 1-27                           [-1, 512, 14, 14]         2,359,808\n",
       "├─ReLU: 1-28                             [-1, 512, 14, 14]         --\n",
       "├─Conv2d: 1-29                           [-1, 512, 14, 14]         2,359,808\n",
       "├─ReLU: 1-30                             [-1, 512, 14, 14]         --\n",
       "├─MaxPool2d: 1-31                        [-1, 512, 7, 7]           --\n",
       "==========================================================================================\n",
       "Total params: 14,714,688\n",
       "Trainable params: 14,714,688\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 15.35\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 103.36\n",
       "Params size (MB): 56.13\n",
       "Estimated Total Size (MB): 160.07\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(vgg16(pretrained = True).features, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 224, 224]        1,792\n",
      "|    └─ReLU: 2-2                         [-1, 64, 224, 224]        --\n",
      "|    └─Conv2d: 2-3                       [-1, 64, 224, 224]        36,928\n",
      "|    └─ReLU: 2-4                         [-1, 64, 224, 224]        --\n",
      "|    └─MaxPool2d: 2-5                    [-1, 64, 112, 112]        --\n",
      "|    └─Conv2d: 2-6                       [-1, 128, 112, 112]       73,856\n",
      "|    └─ReLU: 2-7                         [-1, 128, 112, 112]       --\n",
      "|    └─Conv2d: 2-8                       [-1, 128, 112, 112]       147,584\n",
      "|    └─ReLU: 2-9                         [-1, 128, 112, 112]       --\n",
      "|    └─MaxPool2d: 2-10                   [-1, 128, 56, 56]         --\n",
      "|    └─Conv2d: 2-11                      [-1, 256, 56, 56]         295,168\n",
      "|    └─ReLU: 2-12                        [-1, 256, 56, 56]         --\n",
      "|    └─Conv2d: 2-13                      [-1, 256, 56, 56]         590,080\n",
      "|    └─ReLU: 2-14                        [-1, 256, 56, 56]         --\n",
      "|    └─Conv2d: 2-15                      [-1, 256, 56, 56]         590,080\n",
      "|    └─ReLU: 2-16                        [-1, 256, 56, 56]         --\n",
      "|    └─MaxPool2d: 2-17                   [-1, 256, 28, 28]         --\n",
      "|    └─Conv2d: 2-18                      [-1, 512, 28, 28]         1,180,160\n",
      "|    └─ReLU: 2-19                        [-1, 512, 28, 28]         --\n",
      "|    └─Conv2d: 2-20                      [-1, 512, 28, 28]         2,359,808\n",
      "|    └─ReLU: 2-21                        [-1, 512, 28, 28]         --\n",
      "|    └─Conv2d: 2-22                      [-1, 512, 28, 28]         2,359,808\n",
      "|    └─ReLU: 2-23                        [-1, 512, 28, 28]         --\n",
      "|    └─MaxPool2d: 2-24                   [-1, 512, 14, 14]         --\n",
      "|    └─Conv2d: 2-25                      [-1, 512, 14, 14]         2,359,808\n",
      "|    └─ReLU: 2-26                        [-1, 512, 14, 14]         --\n",
      "|    └─Conv2d: 2-27                      [-1, 512, 14, 14]         2,359,808\n",
      "|    └─ReLU: 2-28                        [-1, 512, 14, 14]         --\n",
      "|    └─Conv2d: 2-29                      [-1, 512, 14, 14]         2,359,808\n",
      "|    └─ReLU: 2-30                        [-1, 512, 14, 14]         --\n",
      "|    └─MaxPool2d: 2-31                   [-1, 512, 7, 7]           --\n",
      "├─Conv2d: 1-1                            [-1, 4096, 1, 1]          102,764,544\n",
      "├─ReLU: 1-2                              [-1, 4096, 1, 1]          --\n",
      "├─Dropout2d: 1-3                         [-1, 4096, 1, 1]          --\n",
      "├─Conv2d: 1-4                            [-1, 4096, 1, 1]          16,781,312\n",
      "├─ReLU: 1-5                              [-1, 4096, 1, 1]          --\n",
      "├─Dropout2d: 1-6                         [-1, 4096, 1, 1]          --\n",
      "├─Conv2d: 1-7                            [-1, 21, 1, 1]            86,037\n",
      "├─ConvTranspose2d: 1-8                   [-1, 21, 4, 4]            7,056\n",
      "├─Conv2d: 1-9                            [-1, 21, 14, 14]          10,773\n",
      "├─ConvTranspose2d: 1-10                  [-1, 21, 10, 10]          7,056\n",
      "├─Conv2d: 1-11                           [-1, 21, 28, 28]          5,397\n",
      "├─ConvTranspose2d: 1-12                  [-1, 21, 88, 88]          112,896\n",
      "==========================================================================================\n",
      "Total params: 134,489,759\n",
      "Trainable params: 134,489,759\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 16.35\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 104.84\n",
      "Params size (MB): 513.04\n",
      "Estimated Total Size (MB): 618.45\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 224, 224]        1,792\n",
       "|    └─ReLU: 2-2                         [-1, 64, 224, 224]        --\n",
       "|    └─Conv2d: 2-3                       [-1, 64, 224, 224]        36,928\n",
       "|    └─ReLU: 2-4                         [-1, 64, 224, 224]        --\n",
       "|    └─MaxPool2d: 2-5                    [-1, 64, 112, 112]        --\n",
       "|    └─Conv2d: 2-6                       [-1, 128, 112, 112]       73,856\n",
       "|    └─ReLU: 2-7                         [-1, 128, 112, 112]       --\n",
       "|    └─Conv2d: 2-8                       [-1, 128, 112, 112]       147,584\n",
       "|    └─ReLU: 2-9                         [-1, 128, 112, 112]       --\n",
       "|    └─MaxPool2d: 2-10                   [-1, 128, 56, 56]         --\n",
       "|    └─Conv2d: 2-11                      [-1, 256, 56, 56]         295,168\n",
       "|    └─ReLU: 2-12                        [-1, 256, 56, 56]         --\n",
       "|    └─Conv2d: 2-13                      [-1, 256, 56, 56]         590,080\n",
       "|    └─ReLU: 2-14                        [-1, 256, 56, 56]         --\n",
       "|    └─Conv2d: 2-15                      [-1, 256, 56, 56]         590,080\n",
       "|    └─ReLU: 2-16                        [-1, 256, 56, 56]         --\n",
       "|    └─MaxPool2d: 2-17                   [-1, 256, 28, 28]         --\n",
       "|    └─Conv2d: 2-18                      [-1, 512, 28, 28]         1,180,160\n",
       "|    └─ReLU: 2-19                        [-1, 512, 28, 28]         --\n",
       "|    └─Conv2d: 2-20                      [-1, 512, 28, 28]         2,359,808\n",
       "|    └─ReLU: 2-21                        [-1, 512, 28, 28]         --\n",
       "|    └─Conv2d: 2-22                      [-1, 512, 28, 28]         2,359,808\n",
       "|    └─ReLU: 2-23                        [-1, 512, 28, 28]         --\n",
       "|    └─MaxPool2d: 2-24                   [-1, 512, 14, 14]         --\n",
       "|    └─Conv2d: 2-25                      [-1, 512, 14, 14]         2,359,808\n",
       "|    └─ReLU: 2-26                        [-1, 512, 14, 14]         --\n",
       "|    └─Conv2d: 2-27                      [-1, 512, 14, 14]         2,359,808\n",
       "|    └─ReLU: 2-28                        [-1, 512, 14, 14]         --\n",
       "|    └─Conv2d: 2-29                      [-1, 512, 14, 14]         2,359,808\n",
       "|    └─ReLU: 2-30                        [-1, 512, 14, 14]         --\n",
       "|    └─MaxPool2d: 2-31                   [-1, 512, 7, 7]           --\n",
       "├─Conv2d: 1-1                            [-1, 4096, 1, 1]          102,764,544\n",
       "├─ReLU: 1-2                              [-1, 4096, 1, 1]          --\n",
       "├─Dropout2d: 1-3                         [-1, 4096, 1, 1]          --\n",
       "├─Conv2d: 1-4                            [-1, 4096, 1, 1]          16,781,312\n",
       "├─ReLU: 1-5                              [-1, 4096, 1, 1]          --\n",
       "├─Dropout2d: 1-6                         [-1, 4096, 1, 1]          --\n",
       "├─Conv2d: 1-7                            [-1, 21, 1, 1]            86,037\n",
       "├─ConvTranspose2d: 1-8                   [-1, 21, 4, 4]            7,056\n",
       "├─Conv2d: 1-9                            [-1, 21, 14, 14]          10,773\n",
       "├─ConvTranspose2d: 1-10                  [-1, 21, 10, 10]          7,056\n",
       "├─Conv2d: 1-11                           [-1, 21, 28, 28]          5,397\n",
       "├─ConvTranspose2d: 1-12                  [-1, 21, 88, 88]          112,896\n",
       "==========================================================================================\n",
       "Total params: 134,489,759\n",
       "Trainable params: 134,489,759\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 16.35\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 104.84\n",
       "Params size (MB): 513.04\n",
       "Estimated Total Size (MB): 618.45\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=255) # ignore (instance) contour\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out,labels):\n",
    "    im = out.argmax(1) # [batch_size x classes x H x W] -> [batch_size x H x W]\n",
    "    correct = 0\n",
    "    correct += (out.argmax(1) == labels).sum() # for each pixel check if match\n",
    "\n",
    "    return 100*correct/(im_size*im_size*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningConfusionMatrix():\n",
    "    def __init__(self, labels, ignore_label=255):\n",
    "        \n",
    "        self.labels = labels\n",
    "        self.ignore_label = ignore_label\n",
    "        self.overall_confusion_matrix = None\n",
    "        self.SMOOTH = 1e-6\n",
    "        self.miou = 0\n",
    "        self.acc  = 0 \n",
    "        \n",
    "    def update_matrix(self, ground_truth, prediction):\n",
    "        # if (ground_truth == self.ignore_label).all():\n",
    "        #     return\n",
    "        \n",
    "        current_confusion_matrix = confusion_matrix(y_true=ground_truth,\n",
    "                                                    y_pred=prediction,\n",
    "                                                    labels=self.labels)\n",
    "        \n",
    "        if self.overall_confusion_matrix is not None:\n",
    "            \n",
    "            self.overall_confusion_matrix += current_confusion_matrix\n",
    "        else:\n",
    "            \n",
    "            self.overall_confusion_matrix = current_confusion_matrix\n",
    "    \n",
    "    def compute_current_mean_intersection_over_union(self):\n",
    "        \n",
    "        intersection = np.diag(self.overall_confusion_matrix)\n",
    "        ground_truth_set = self.overall_confusion_matrix.sum(axis=1)\n",
    "        predicted_set = self.overall_confusion_matrix.sum(axis=0)\n",
    "        union =  ground_truth_set + predicted_set - intersection\n",
    "\n",
    "        intersection_over_union = (intersection + self.SMOOTH) / (union.astype(np.float32) + self.SMOOTH)\n",
    "        mean_intersection_over_union = np.mean(intersection_over_union)\n",
    "\n",
    "        pixel_accuracy = np.sum(intersection)/np.sum(self.overall_confusion_matrix)\n",
    "\n",
    "        self.miou = mean_intersection_over_union\n",
    "        self.acc  = pixel_accuracy\n",
    "\n",
    "\n",
    "        return mean_intersection_over_union,pixel_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 0],\n",
       "       [0, 1, 2],\n",
       "       [2, 1, 3]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actu = [2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1, 2]\n",
    "y_pred = [0, 0, 2, 1, 0, 2, 1, 0, 2, 0, 2, 2]\n",
    "conf = confusion_matrix(y_actu, y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "12\n",
      "0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "dia = np.diag(conf).sum()\n",
    "sumall = np.sum(conf)\n",
    "print(dia)\n",
    "print(sumall)\n",
    "print(dia/sumall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                          | 0/183 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (3 x 3). Kernel size: (7 x 7). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-55-210e926fa3b1>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    415\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 416\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (3 x 3). Kernel size: (7 x 7). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "    for batch_idx, (data, targets) in loop:\n",
    "        data = data.to(device=device)\n",
    "        if (int(targets.max()) == int(1)): # scale from [0,1] -> [0,255]\n",
    "            targets = targets*255\n",
    "        targets = targets.squeeze(1).to(device=device, dtype=torch.int64)\n",
    "        \n",
    "        # forward pass\n",
    "        out = model(data)['out']\n",
    "        loss = criterion(out, targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent\n",
    "        optimizer.step()\n",
    "\n",
    "        # update progress bar\n",
    "        acc = accuracy(out, targets)\n",
    "        loop.set_description(f\"Epoch [{epoch}/{num_epochs}]\")\n",
    "        loop.set_postfix(loss = loss.item(), acc=f\"{acc:.0f}%\")\n",
    "\n",
    "\n",
    "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one epoch with batch_size:16, im_size: 112 was 13 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the helper function\n",
    "def decode_segmap(image, nc=21):\n",
    "  \n",
    "  label_colors = np.array([(0, 0, 0),  # 0=background\n",
    "               # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle\n",
    "               (128, 0, 0), (0, 128, 0), (128, 128, 0), (0, 0, 128), (128, 0, 128),\n",
    "               # 6=bus, 7=car, 8=cat, 9=chair, 10=cow\n",
    "               (0, 128, 128), (128, 128, 128), (64, 0, 0), (192, 0, 0), (64, 128, 0),\n",
    "               # 11=dining table, 12=dog, 13=horse, 14=motorbike, 15=person\n",
    "               (192, 128, 0), (64, 0, 128), (192, 0, 128), (64, 128, 128), (192, 128, 128),\n",
    "               # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\n",
    "               (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0), (0, 64, 128)])\n",
    "\n",
    "  r = np.zeros_like(image).astype(np.uint8)\n",
    "  g = np.zeros_like(image).astype(np.uint8)\n",
    "  b = np.zeros_like(image).astype(np.uint8)\n",
    "  \n",
    "  for l in range(0, nc):\n",
    "    idx = image == l\n",
    "    r[idx] = label_colors[l, 0]\n",
    "    g[idx] = label_colors[l, 1]\n",
    "    b[idx] = label_colors[l, 2]\n",
    "    \n",
    "  rgb = np.stack([r, g, b], axis=2)\n",
    "  return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "labels = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "cm = RunningConfusionMatrix(labels=labels, ignore_label=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, batch_size=4, overlay=False):\n",
    "    model.eval()\n",
    "\n",
    "    loop = tqdm(enumerate(test_loader), total=len(test_loader), leave=False)\n",
    "    for batch_idx, (data, targets) in loop:\n",
    "        image, target = next(iter(test_loader))\n",
    "        image, target = image.to(device), target.to(device)\n",
    "        if (int(target.max()) == int(1)):\n",
    "            target = target*255\n",
    "        out = model(image)['out']\n",
    "\n",
    "        image, target, out = image.cpu(), target.cpu(), out.cpu()\n",
    "        image, target, out = image.to('cpu'), target.to('cpu'), out.to('cpu')\n",
    "\n",
    "\n",
    "        cm.update_matrix(target.view(-1), out.argmax(1).view(-1))\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            for idx in range(batch_size):\n",
    "                \n",
    "                om = torch.argmax(out[idx].squeeze(), dim=0).detach().cpu().numpy()\n",
    "\n",
    "                input_image  = image[idx].permute(1,2,0) * std[0] + torch.FloatTensor(mean)\n",
    "                target_image = decode_segmap(target[idx].squeeze(0))\n",
    "                output_image = decode_segmap(om)\n",
    "\n",
    "                if (overlay):\n",
    "                    axes=[]\n",
    "                    fig=plt.figure(figsize=(6,6))\n",
    "                    plt.imshow(torch.FloatTensor(output_image) * 0.0033 + input_image * 0.65 )\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    axes=[]\n",
    "                    fig=plt.figure(figsize=(21,21))\n",
    "                    axes.append( fig.add_subplot(1, 3, 1) )\n",
    "                    plt.imshow( input_image  )\n",
    "                    axes[-1].set_title(\"input\")\n",
    "\n",
    "                    axes.append( fig.add_subplot(1, 3, 2) )\n",
    "                    plt.imshow( target_image )\n",
    "                    axes[-1].set_title(\"target\")\n",
    "\n",
    "                    axes.append( fig.add_subplot(1, 3, 3) )\n",
    "                    plt.imshow( output_image )\n",
    "                    axes[-1].set_title(\"output\")\n",
    "\n",
    "                    plt.show()\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    model.train()\n",
    "    print(f\"mean intersection over union: {cm.compute_current_mean_intersection_over_union()}\")   \n",
    "    plot_confusion_matrix(cm.overall_confusion_matrix,labels)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, test_loader, overlay=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"0: background\",\"1: aeroplane\", \"2: bicycle\", \"3: bird\", \"4: boat\", \"5: bottle\", \"6: bus\", \"7: car\", \"8: cat\", \"9: chair\", \"10: cow\", \"11: dining table\", \"12: dog\", \"13: horse\", \"14: motorbike\", \"15: person \",\"16: potted plant\", \"17: sheep\", \"18: sofa\", \"19: train\", \"20: tv/monitor\"]\n",
    "plot_confusion_matrix(cm.overall_confusion_matrix,labels, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = cm.compute_current_mean_intersection_over_union()\n",
    "print(\"the mIoU is: \\t\\t%.2f\"  % metrics[0])\n",
    "print(\"the pixel accuracy is: \\t%.2f\"  % metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palette = torch.tensor([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\n",
    "# colors = torch.as_tensor([i for i in range(21)])[:, None] * palette\n",
    "# colors = (colors % 255).numpy().astype(\"uint8\")\n",
    "\n",
    "# # plot the semantic segmentation predictions of 21 classes in each color\n",
    "# r = Image.fromarray(out[0].argmax(0).byte().cpu().numpy()).resize(im.size)\n",
    "# r.putpalette(colors)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"0: background\", \"1: aeroplane\", \"2: bicycle\", \"3: bird\", \"4: boat\", \"5: bottle\", \"6: bus\", \"7: car\", \"8: cat\", \"9: chair\", \"10: cow\", \"11: dining table\", \"12: dog\", \"13: horse\", \"14: motorbike\", \"15: person \",\"16: potted plant\", \"17: sheep\", \"18: sofa\", \"19: train\", \"20: tv/monitor\"]\n",
    "\n",
    "width = 2\n",
    "height = 2\n",
    "rows = 6\n",
    "cols = 7\n",
    "\n",
    "axes=[]\n",
    "fig=plt.figure(figsize=(13,13))\n",
    "\n",
    "for a in range(21):\n",
    "    # b = np.random.randint(7, size=(height,width))\n",
    "    axes.append( fig.add_subplot(rows, cols, a+1) )\n",
    "    subplot_title=(str(labels[a]))\n",
    "    axes[-1].set_title(subplot_title,fontweight=\"bold\")\n",
    "    z = np.array([[a, a],[a, a]])\n",
    "    plt.imshow(decode_segmap(z))\n",
    "    plt.axis('off')  \n",
    "# fig.tight_layout()    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model1.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
