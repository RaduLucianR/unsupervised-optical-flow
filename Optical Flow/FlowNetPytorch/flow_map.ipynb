{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('deeplearning': conda)",
   "metadata": {
    "interpreter": {
     "hash": "2bd64c8ed255417a6a958191fccf12000a54ee5f0beba3cab0ff9b85bda4afbd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\Users\\20182475\\OneDrive - TU Eindhoven\\TUe documents\\BAU3\\Honors - Smart Mobility\\deeplearning-notebooks\\Optical Flow\\FlowNetPytorch\\models\\util.py:10: ImportWarning: failed to load custom correlation modulewhich is needed for FlowNetC\n  warnings.warn(\"failed to load custom correlation module\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import flow_transforms\n",
    "import models\n",
    "import datasets\n",
    "from multiscaleloss import multiscaleEPE, realEPE\n",
    "from util import flow2rgb, AverageMeter, save_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=[0.45,0.432,0.411]\n",
    "mean=[0,0,0]\n",
    "input_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "    transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "    transforms.Normalize(mean=mean, std=[1,1,1])\n",
    "])\n",
    "target_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "    transforms.Normalize(mean=[0,0],std=[20*0+1,20*0+1])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_transform = flow_transforms.Compose([\n",
    "            flow_transforms.RandomTranslate(10),\n",
    "            flow_transforms.RandomRotate(10,5),\n",
    "            flow_transforms.RandomCrop((320,448)),\n",
    "            flow_transforms.RandomVerticalFlip(),\n",
    "            flow_transforms.RandomHorizontalFlip()\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r\"KITTI_split\\training_80\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=> fetching img pairs in 'KITTI_split\\training_80'\n144 samples found, 115 train samples and 29 test samples \n"
     ]
    }
   ],
   "source": [
    "print(\"=> fetching img pairs in '{}'\".format(data))\n",
    "train_set, test_set = datasets.__dict__[\"KITTI_noc\"](\n",
    "    data,\n",
    "    transform=input_transform,\n",
    "    target_transform=target_transform,\n",
    "    co_transform=None,\n",
    "    split=0.8\n",
    ")\n",
    "print('{} samples found, {} train samples and {} test samples '.format(len(test_set)+len(train_set),\n",
    "                                                                        len(train_set),\n",
    "                                                                        len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=4,\n",
    "        num_workers=1, pin_memory=True, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=4,\n",
    "    num_workers=1, pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, target = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "im1 = input[0][i].numpy().transpose(1, 2, 0)\n",
    "im2 = input[1][i].numpy().transpose(1, 2, 0)\n",
    "im3 = input[0][i+1].numpy().transpose(1, 2, 0)\n",
    "im4 = input[1][i+1].numpy().transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"1\", im1)\n",
    "cv2.imshow(\"2\", im2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "## MSE of two input images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "\t# the 'Mean Squared Error' between the two images is the\n",
    "\t# sum of the squared difference between the two images;\n",
    "\t# NOTE: the two images must have the same dimension\n",
    "\terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "\terr /= float(imageA.shape[0] * imageA.shape[1])\n",
    "\t\n",
    "\t# return the MSE, the lower the error, the more \"similar\"\n",
    "\t# the two images are\n",
    "\treturn err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.19613990740005707"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "mse(im1,im2)"
   ]
  },
  {
   "source": [
    "## Applying Flow Map on Image 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg1 = target[0].permute(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = np.zeros_like(im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1242, 375)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "width = len(im1[0])\n",
    "height = len(im1)\n",
    "width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "image 1 shape: \t(375, 1242, 3)\nrecon shape: \t(375, 1242, 3)\ntarget shape: \t(375, 1242, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"image 1 shape: \\t{im1.shape}\")\n",
    "print(f\"recon shape: \\t{recon.shape}\")\n",
    "print(f\"target shape: \\t{tg1.numpy().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 8.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# recon = np.zeros_like(im1)\n",
    "recon = im1.copy()\n",
    "\n",
    "for h in range(height):\n",
    "    for w in range(width):\n",
    "        vec = tg1[h,w,:]\n",
    "        dx = round(vec[0].item())\n",
    "        dy = round(vec[1].item())\n",
    "        h_ = h+dy if h+dy < height else height-1\n",
    "        w_ = w+dx if w+dx < width else width-1\n",
    "        \n",
    "        recon[h_, w_, :] = im1[h, w, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"image2\", im2)\n",
    "cv2.imshow(\"recon\", recon)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mse im1 and im2: 0.20\nmse im2 and recon: 0.18737329857721532\n"
     ]
    }
   ],
   "source": [
    "print(f\"mse im1 and im2: {mse(im1,im2):.2f}\")\n",
    "print(f\"mse im2 and recon: {mse(im2,recon)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}